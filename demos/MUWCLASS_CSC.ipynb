{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div class=\"bk-root\">\n",
       "        <a href=\"https://bokeh.org\" target=\"_blank\" class=\"bk-logo bk-logo-small bk-logo-notebook\"></a>\n",
       "        <span id=\"1001\">Loading BokehJS ...</span>\n",
       "    </div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": "(function(root) {\n  function now() {\n    return new Date();\n  }\n\n  const force = true;\n\n  if (typeof root._bokeh_onload_callbacks === \"undefined\" || force === true) {\n    root._bokeh_onload_callbacks = [];\n    root._bokeh_is_loading = undefined;\n  }\n\nconst JS_MIME_TYPE = 'application/javascript';\n  const HTML_MIME_TYPE = 'text/html';\n  const EXEC_MIME_TYPE = 'application/vnd.bokehjs_exec.v0+json';\n  const CLASS_NAME = 'output_bokeh rendered_html';\n\n  /**\n   * Render data to the DOM node\n   */\n  function render(props, node) {\n    const script = document.createElement(\"script\");\n    node.appendChild(script);\n  }\n\n  /**\n   * Handle when an output is cleared or removed\n   */\n  function handleClearOutput(event, handle) {\n    const cell = handle.cell;\n\n    const id = cell.output_area._bokeh_element_id;\n    const server_id = cell.output_area._bokeh_server_id;\n    // Clean up Bokeh references\n    if (id != null && id in Bokeh.index) {\n      Bokeh.index[id].model.document.clear();\n      delete Bokeh.index[id];\n    }\n\n    if (server_id !== undefined) {\n      // Clean up Bokeh references\n      const cmd_clean = \"from bokeh.io.state import curstate; print(curstate().uuid_to_server['\" + server_id + \"'].get_sessions()[0].document.roots[0]._id)\";\n      cell.notebook.kernel.execute(cmd_clean, {\n        iopub: {\n          output: function(msg) {\n            const id = msg.content.text.trim();\n            if (id in Bokeh.index) {\n              Bokeh.index[id].model.document.clear();\n              delete Bokeh.index[id];\n            }\n          }\n        }\n      });\n      // Destroy server and session\n      const cmd_destroy = \"import bokeh.io.notebook as ion; ion.destroy_server('\" + server_id + \"')\";\n      cell.notebook.kernel.execute(cmd_destroy);\n    }\n  }\n\n  /**\n   * Handle when a new output is added\n   */\n  function handleAddOutput(event, handle) {\n    const output_area = handle.output_area;\n    const output = handle.output;\n\n    // limit handleAddOutput to display_data with EXEC_MIME_TYPE content only\n    if ((output.output_type != \"display_data\") || (!Object.prototype.hasOwnProperty.call(output.data, EXEC_MIME_TYPE))) {\n      return\n    }\n\n    const toinsert = output_area.element.find(\".\" + CLASS_NAME.split(' ')[0]);\n\n    if (output.metadata[EXEC_MIME_TYPE][\"id\"] !== undefined) {\n      toinsert[toinsert.length - 1].firstChild.textContent = output.data[JS_MIME_TYPE];\n      // store reference to embed id on output_area\n      output_area._bokeh_element_id = output.metadata[EXEC_MIME_TYPE][\"id\"];\n    }\n    if (output.metadata[EXEC_MIME_TYPE][\"server_id\"] !== undefined) {\n      const bk_div = document.createElement(\"div\");\n      bk_div.innerHTML = output.data[HTML_MIME_TYPE];\n      const script_attrs = bk_div.children[0].attributes;\n      for (let i = 0; i < script_attrs.length; i++) {\n        toinsert[toinsert.length - 1].firstChild.setAttribute(script_attrs[i].name, script_attrs[i].value);\n        toinsert[toinsert.length - 1].firstChild.textContent = bk_div.children[0].textContent\n      }\n      // store reference to server id on output_area\n      output_area._bokeh_server_id = output.metadata[EXEC_MIME_TYPE][\"server_id\"];\n    }\n  }\n\n  function register_renderer(events, OutputArea) {\n\n    function append_mime(data, metadata, element) {\n      // create a DOM node to render to\n      const toinsert = this.create_output_subarea(\n        metadata,\n        CLASS_NAME,\n        EXEC_MIME_TYPE\n      );\n      this.keyboard_manager.register_events(toinsert);\n      // Render to node\n      const props = {data: data, metadata: metadata[EXEC_MIME_TYPE]};\n      render(props, toinsert[toinsert.length - 1]);\n      element.append(toinsert);\n      return toinsert\n    }\n\n    /* Handle when an output is cleared or removed */\n    events.on('clear_output.CodeCell', handleClearOutput);\n    events.on('delete.Cell', handleClearOutput);\n\n    /* Handle when a new output is added */\n    events.on('output_added.OutputArea', handleAddOutput);\n\n    /**\n     * Register the mime type and append_mime function with output_area\n     */\n    OutputArea.prototype.register_mime_type(EXEC_MIME_TYPE, append_mime, {\n      /* Is output safe? */\n      safe: true,\n      /* Index of renderer in `output_area.display_order` */\n      index: 0\n    });\n  }\n\n  // register the mime type if in Jupyter Notebook environment and previously unregistered\n  if (root.Jupyter !== undefined) {\n    const events = require('base/js/events');\n    const OutputArea = require('notebook/js/outputarea').OutputArea;\n\n    if (OutputArea.prototype.mime_types().indexOf(EXEC_MIME_TYPE) == -1) {\n      register_renderer(events, OutputArea);\n    }\n  }\n  if (typeof (root._bokeh_timeout) === \"undefined\" || force === true) {\n    root._bokeh_timeout = Date.now() + 5000;\n    root._bokeh_failed_load = false;\n  }\n\n  const NB_LOAD_WARNING = {'data': {'text/html':\n     \"<div style='background-color: #fdd'>\\n\"+\n     \"<p>\\n\"+\n     \"BokehJS does not appear to have successfully loaded. If loading BokehJS from CDN, this \\n\"+\n     \"may be due to a slow or bad network connection. Possible fixes:\\n\"+\n     \"</p>\\n\"+\n     \"<ul>\\n\"+\n     \"<li>re-rerun `output_notebook()` to attempt to load from CDN again, or</li>\\n\"+\n     \"<li>use INLINE resources instead, as so:</li>\\n\"+\n     \"</ul>\\n\"+\n     \"<code>\\n\"+\n     \"from bokeh.resources import INLINE\\n\"+\n     \"output_notebook(resources=INLINE)\\n\"+\n     \"</code>\\n\"+\n     \"</div>\"}};\n\n  function display_loaded() {\n    const el = document.getElementById(\"1001\");\n    if (el != null) {\n      el.textContent = \"BokehJS is loading...\";\n    }\n    if (root.Bokeh !== undefined) {\n      if (el != null) {\n        el.textContent = \"BokehJS \" + root.Bokeh.version + \" successfully loaded.\";\n      }\n    } else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(display_loaded, 100)\n    }\n  }\n\n  function run_callbacks() {\n    try {\n      root._bokeh_onload_callbacks.forEach(function(callback) {\n        if (callback != null)\n          callback();\n      });\n    } finally {\n      delete root._bokeh_onload_callbacks\n    }\n    console.debug(\"Bokeh: all callbacks have finished\");\n  }\n\n  function load_libs(css_urls, js_urls, callback) {\n    if (css_urls == null) css_urls = [];\n    if (js_urls == null) js_urls = [];\n\n    root._bokeh_onload_callbacks.push(callback);\n    if (root._bokeh_is_loading > 0) {\n      console.debug(\"Bokeh: BokehJS is being loaded, scheduling callback at\", now());\n      return null;\n    }\n    if (js_urls == null || js_urls.length === 0) {\n      run_callbacks();\n      return null;\n    }\n    console.debug(\"Bokeh: BokehJS not loaded, scheduling load and callback at\", now());\n    root._bokeh_is_loading = css_urls.length + js_urls.length;\n\n    function on_load() {\n      root._bokeh_is_loading--;\n      if (root._bokeh_is_loading === 0) {\n        console.debug(\"Bokeh: all BokehJS libraries/stylesheets loaded\");\n        run_callbacks()\n      }\n    }\n\n    function on_error(url) {\n      console.error(\"failed to load \" + url);\n    }\n\n    for (let i = 0; i < css_urls.length; i++) {\n      const url = css_urls[i];\n      const element = document.createElement(\"link\");\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.rel = \"stylesheet\";\n      element.type = \"text/css\";\n      element.href = url;\n      console.debug(\"Bokeh: injecting link tag for BokehJS stylesheet: \", url);\n      document.body.appendChild(element);\n    }\n\n    for (let i = 0; i < js_urls.length; i++) {\n      const url = js_urls[i];\n      const element = document.createElement('script');\n      element.onload = on_load;\n      element.onerror = on_error.bind(null, url);\n      element.async = false;\n      element.src = url;\n      console.debug(\"Bokeh: injecting script tag for BokehJS library: \", url);\n      document.head.appendChild(element);\n    }\n  };\n\n  function inject_raw_css(css) {\n    const element = document.createElement(\"style\");\n    element.appendChild(document.createTextNode(css));\n    document.body.appendChild(element);\n  }\n\n  const js_urls = [\"https://cdn.bokeh.org/bokeh/release/bokeh-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-gl-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-widgets-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-tables-2.4.3.min.js\", \"https://cdn.bokeh.org/bokeh/release/bokeh-mathjax-2.4.3.min.js\"];\n  const css_urls = [];\n\n  const inline_js = [    function(Bokeh) {\n      Bokeh.set_log_level(\"info\");\n    },\nfunction(Bokeh) {\n    }\n  ];\n\n  function run_inline_js() {\n    if (root.Bokeh !== undefined || force === true) {\n          for (let i = 0; i < inline_js.length; i++) {\n      inline_js[i].call(root, root.Bokeh);\n    }\nif (force === true) {\n        display_loaded();\n      }} else if (Date.now() < root._bokeh_timeout) {\n      setTimeout(run_inline_js, 100);\n    } else if (!root._bokeh_failed_load) {\n      console.log(\"Bokeh: BokehJS failed to load within specified timeout.\");\n      root._bokeh_failed_load = true;\n    } else if (force !== true) {\n      const cell = $(document.getElementById(\"1001\")).parents('.cell').data().cell;\n      cell.output_area.append_execute_result(NB_LOAD_WARNING)\n    }\n  }\n\n  if (root._bokeh_is_loading === 0) {\n    console.debug(\"Bokeh: BokehJS loaded, going straight to plotting\");\n    run_inline_js();\n  } else {\n    load_libs(css_urls, js_urls, function() {\n      console.debug(\"Bokeh: BokehJS plotting callback run at\", now());\n      run_inline_js();\n    });\n  }\n}(window));",
      "application/vnd.bokehjs_load.v0+json": ""
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from astropy import units as u\n",
    "from astropy.coordinates import SkyCoord, Angle\n",
    "from gdpyc import GasMap, DustMap\n",
    "import time\n",
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "import matplotlib.pyplot as plt\n",
    "from bokeh.io import output_notebook\n",
    "\n",
    "output_notebook()\n",
    "\n",
    "\n",
    "import sys  \n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '../')\n",
    "\n",
    "from muwclass_library import class_prepare_FGL, class_train_model_and_classify, class_save_res\n",
    "from nway_match import nway_CSC_matching_merged_mw, CSCviewsearch\n",
    "from muwclass_CSC import stack_astrometry, write_to_html_file, combine_class_result, process_crossmatching\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# autoreload\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a circular region of interest with detections available from CSCv2 (ACIS chips only)\n",
    "\n",
    "* field_name\n",
    "* RA, DEC, radius: RA (right ascension) and Dec (declination) coordinates and radius (in arcmin) of the field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "'''\n",
    "field_name = 'NGC3532'\n",
    "-\n",
    "RA = 166.28875\n",
    "\n",
    "DEC = -58.85\n",
    "\n",
    "radius = 2 # in arcmin \n",
    "\n",
    "field_name = 'J1109.4-6115e'\n",
    "RA = 167.362\n",
    "DEC =-61.259\n",
    "radius = 30\n",
    "'''\n",
    "\n",
    "# dictionary of cluster name and CSCview cone search parameters. Radius is in arcmins\n",
    "clusters_dict = {'NGC3532': {'ra': 166.28875, 'dec': -58.85, 'radius': 12, 'create_perobs': False},\n",
    "'Trumpler18': {'ra': 167.9712649, 'dec': -60.6184559, 'radius': 12, 'create_perobs': True},\n",
    "'IC2395': {'ra': 130.6191230, 'dec': -48.1137862, 'radius': 12, 'create_perobs': True},\n",
    "'IC2395_CXO': {'ra': 130.6191230, 'dec': -48.1137862, 'radius': 12, 'create_perobs': True},\n",
    "'IC2395_CXO_noconversion': {'ra': 130.6191230, 'dec': -48.1137862, 'radius': 12, 'create_perobs': True},\n",
    "'NGC2169': {'ra': 92.1011374, 'dec': 13.9711171, 'radius': 12, 'create_perobs': True},\n",
    "'NGC2169_CXO': {'ra': 92.1011374, 'dec': 13.9711171, 'radius': 12, 'create_perobs': True},\n",
    "'NGC7160': {'ra': 328.4575412, 'dec': 62.5926872, 'radius': 12, 'create_perobs': True},\n",
    "'J1256.9+2736': {'ra': 194.2417, 'dec': 27.6076, 'radius': 0.2127*60, 'create_perobs': True},\n",
    "'J1435.4+3338': {'ra': 218.8526, 'dec': 33.6367, 'radius': 0.1853*60, 'create_perobs': True},\n",
    "'J1115.1-6118': {'ra': 168.7757, 'dec': -61.3085, 'radius': 0.0373*60, 'create_perobs': True},\n",
    "}\n",
    "\n",
    "# select cluster\n",
    "field_name = 'J1115.1-6118'\n",
    "RA = clusters_dict[field_name]['ra']\n",
    "DEC = clusters_dict[field_name]['dec']\n",
    "radius = clusters_dict[field_name]['radius']\n",
    "create_perobs = clusters_dict[field_name]['create_perobs']\n",
    "\n",
    "# field_name = '2CXOJ110432.8-584405'\n",
    "# RA = 166.136875\t\n",
    "# DEC = -58.734875\n",
    "# radius = 3/60 # in arcmins\n",
    "\n",
    "# Some other examples of regions of interest \n",
    "\n",
    "#field_name = 'Trumpler18'\n",
    "#RA, DEC,radius = 167.9712649, -60.6184559, 12\n",
    "\n",
    "\n",
    "# creating the directories for saving the data and results \n",
    "\n",
    "data_dir = f'./data/{field_name}' # data directory to save the file\n",
    "\n",
    "dir_out = f'./data/{field_name}' # classification results directory\n",
    "dir_plot = dir_out+'/plot' # plots directory\n",
    "nway_dir = f'./data/{field_name}/nway' \n",
    "Path(data_dir).mkdir(parents=True, exist_ok=True)\n",
    "Path(dir_out).mkdir(parents=True, exist_ok=True)\n",
    "Path(dir_plot).mkdir(parents=True, exist_ok=True)\n",
    "Path(nway_dir).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for CSC sources and crossmatch to MW catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "--2024-03-06 21:32:58--  http://cda.cfa.harvard.edu/csccli/getProperties?query=SELECT%20DISTINCT%20dbo.separation(m.ra,m.dec,168.7757,-61.3085)%20as%20separation,m.name,m.ra,m.dec,m.err_ellipse_r0,m.err_ellipse_r1,m.err_ellipse_ang,m.significance,m.likelihood_class,m.conf_flag,m.dither_warning_flag,m.extent_flag,m.pileup_flag,m.sat_src_flag,m.streak_src_flag,m.var_flag,m.var_inter_hard_flag,m.flux_aper90_b,m.flux_aper90_lolim_b,m.flux_aper90_hilim_b,m.flux_aper90_h,m.flux_aper90_lolim_h,m.flux_aper90_hilim_h,m.flux_aper90_m,m.flux_aper90_lolim_m,m.flux_aper90_hilim_m,m.flux_aper90_s,m.flux_aper90_lolim_s,m.flux_aper90_hilim_s,m.flux_aper90_avg_b,m.flux_aper90_avg_lolim_b,m.flux_aper90_avg_hilim_b,m.flux_aper90_avg_h,m.flux_aper90_avg_lolim_h,m.flux_aper90_avg_hilim_h,m.flux_aper90_avg_m,m.flux_aper90_avg_lolim_m,m.flux_aper90_avg_hilim_m,m.flux_aper90_avg_s,m.flux_aper90_avg_lolim_s,m.flux_aper90_avg_hilim_s,m.var_intra_index_b,m.var_intra_prob_b,m.ks_intra_prob_b,m.kp_intra_prob_b,m.var_inter_index_b,m.var_inter_prob_b,m.var_inter_sigma_b,m.nh_gal,m.flux_powlaw,m.flux_powlaw_lolim,m.flux_powlaw_hilim,m.powlaw_gamma,m.powlaw_gamma_lolim,m.powlaw_gamma_hilim,m.powlaw_gamma_rhat,m.powlaw_nh,m.powlaw_nh_lolim,m.powlaw_nh_hilim,m.powlaw_nh_rhat,m.powlaw_ampl,m.powlaw_ampl_lolim,m.powlaw_ampl_hilim,m.powlaw_ampl_rhat,m.powlaw_stat,m.flux_bb,m.flux_bb_lolim,m.flux_bb_hilim,m.bb_kt,m.bb_kt_lolim,m.bb_kt_hilim,m.bb_kt_rhat,m.bb_nh,m.bb_nh_lolim,m.bb_nh_hilim,m.bb_nh_rhat,m.bb_ampl,m.bb_ampl_lolim,m.bb_ampl_hilim,m.bb_ampl_rhat,m.bb_stat,m.flux_brems,m.flux_brems_lolim,m.flux_brems_hilim,m.brems_kt,m.brems_kt_lolim,m.brems_kt_hilim,m.brems_kt_rhat,m.brems_nh,m.brems_nh_lolim,m.brems_nh_hilim,m.brems_nh_rhat,m.brems_norm,m.brems_norm_lolim,m.brems_norm_hilim,m.brems_norm_rhat,m.brems_stat,m.flux_apec,m.flux_apec_lolim,m.flux_apec_hilim,m.apec_kt,m.apec_kt_lolim,m.apec_kt_hilim,m.apec_kt_rhat,m.apec_abund,m.apec_abund_lolim,m.apec_abund_hilim,m.apec_abund_rhat,m.apec_z,m.apec_z_lolim,m.apec_z_hilim,m.apec_z_rhat,m.apec_nh,m.apec_nh_lolim,m.apec_nh_hilim,m.apec_nh_rhat,m.apec_norm,m.apec_norm_lolim,m.apec_norm_hilim,m.apec_norm_rhat,m.apec_stat,o.obsid,o.region_id,o.obi,o.ra_pnt,o.dec_pnt,o.gti_obs,o.gti_end,o.instrument,o.grating,o.datamode,o.theta,o.phi,o.src_cnts_aper90_b,o.src_cnts_aper90_lolim_b,o.src_cnts_aper90_hilim_b,o.flux_significance_b,o.conf_code,o.dither_warning_flag,o.edge_code,o.extent_code,o.multi_chip_code,o.pileup_warning,o.sat_src_flag,o.streak_src_flag,o.var_code,o.flux_aper90_b,o.flux_aper90_lolim_b,o.flux_aper90_hilim_b,o.flux_aper90_h,o.flux_aper90_lolim_h,o.flux_aper90_hilim_h,o.flux_aper90_m,o.flux_aper90_lolim_m,o.flux_aper90_hilim_m,o.flux_aper90_s,o.flux_aper90_lolim_s,o.flux_aper90_hilim_s,o.var_index_b,o.var_prob_b,o.ks_prob_b,o.kp_prob_b,o.var_sigma_b,o.var_mean_b,o.var_min_b,o.var_max_b%20FROM%20master_source%20m%20,%20master_stack_assoc%20a%20,%20observation_source%20o%20,%20stack_observation_assoc%20b%20,%20stack_source%20s%20WHERE%20(((%20(%20m.dec%20BETWEEN%20-61.345800000000004%20AND%20-61.2712%20)%20AND%20(%20m.ra%20BETWEEN%20168.69800677879232%20AND%20168.85339322120768%20)%20)%20AND%20dbo.cone_distance(m.ra,m.dec,168.7757,-61.3085)%3C=2.238))%20AND%20(m.name%20=%20a.name)%20AND%20(s.detect_stack_id%20=%20a.detect_stack_id%20and%20s.region_id%20=%20a.region_id)%20AND%20(s.detect_stack_id%20=%20b.detect_stack_id%20and%20s.region_id%20=%20b.region_id)%20AND%20(o.obsid%20=%20b.obsid%20and%20o.obi%20=%20b.obi%20and%20o.region_id%20=%20b.region_id)ORDER%20BY%20separation%20ASC,%20name%20ASC\n",
      "Resolving cda.cfa.harvard.edu (cda.cfa.harvard.edu)... 131.142.198.67\n",
      "Connecting to cda.cfa.harvard.edu (cda.cfa.harvard.edu)|131.142.198.67|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: unspecified [text/plain]\n",
      "Saving to: ‘./data/J1115.1-6118/J1115.1-6118_wget.txt’\n",
      "\n",
      "     0K .......... .......... .......... .......... .......... 1.34M\n",
      "    50K .......... .......... .......... .......... .......... 2.75M\n",
      "   100K .......... .......... .......... .......... .......... 88.0M\n",
      "   150K .......... .......... .......... .......... .......... 20.8M\n",
      "   200K .......... .......... .......... .......... .......... 2.91M\n",
      "   250K .......... .......... .......... .......... .......... 86.7M\n",
      "   300K .......... .......... .......... .......... .......... 87.7M\n",
      "   350K .......... .......... .......... .......... .......... 42.9M\n",
      "   400K .......... .......... .......... .......... .......... 2.74M\n",
      "   450K .......... .......... .......... .......... .......... 25.4M\n",
      "   500K .......... .......... .......... .......... .......... 6.48M\n",
      "   550K .......... .......... .......... .......... .......... 6.46M\n",
      "   600K .......... .......... .......... .......... .......... 6.16M\n",
      "   650K .......... .......... .......... .......... .......... 3.09M\n",
      "   700K .......... .......... .......... .......... .......... 6.36M\n",
      "   750K .......... .......... .......... .......... .......... 6.19M\n",
      "   800K .......... .......... .......... .......... .......... 3.03M\n",
      "   850K .......... .......... .......... .......... .......... 6.37M\n",
      "   900K .......... .......... .......... .......... .......... 6.08M\n",
      "   950K .......... .......... .......... .......... .......... 3.61M\n",
      "  1000K .......... .......... .......... .......... .......... 4.39M\n",
      "  1050K .......... .......... .......... .......... .......... 7.79M\n",
      "  1100K .......... .......... .......... .......... .......... 3.66M\n",
      "  1150K .......... .......... .......... .......... .......... 6.02M\n",
      "  1200K .......... .......... .......... .......... .......... 4.42M\n",
      "  1250K .......... .......... .......... .......... .......... 2.96M\n",
      "  1300K .......... .......... .......... .......... .......... 6.32M\n",
      "  1350K .......... .......... .......... .......... .......... 6.26M\n",
      "  1400K .......... .......... .......... .......... .......... 3.50M\n",
      "  1450K .......... .......... .......... .......... .......... 6.52M\n",
      "  1500K .......... .......... .......... .......... .......... 6.30M\n",
      "  1550K .......... .......... .......... .......... .......... 3.49M\n",
      "  1600K .......... .......... .......... .......... .......... 5.21M\n",
      "  1650K .......... .......... .......... .......... .......... 5.65M\n",
      "  1700K .......... .......... .......... .......... .......... 3.43M\n",
      "  1750K .......... .......... .......... .......... .......... 5.85M\n",
      "  1800K .......... .......... .......... .......... .......... 6.30M\n",
      "  1850K .......... .......... .......... .......... .......... 6.60M\n",
      "  1900K .......... .......... .......... .......... .......... 3.48M\n",
      "  1950K .......... .......... .......... .......... .......... 6.44M\n",
      "  2000K .......... .......... .......... .......... .......... 4.77M\n",
      "  2050K .......... .......... .......... .......... .......... 3.31M\n",
      "  2100K .......... .......... .......... .......... .......... 6.54M\n",
      "  2150K .......... .......... .......... .......... .......... 5.14M\n",
      "  2200K .......... .......... .......... .......... .......... 4.78M\n",
      "  2250K .......... .......... .......... .......... ....       7.95M=0.5s\n",
      "\n",
      "2024-03-06 21:32:59 (4.92 MB/s) - ‘./data/J1115.1-6118/J1115.1-6118_wget.txt’ saved [2349684]\n",
      "\n",
      "FINISHED --2024-03-06 21:32:59--\n",
      "Total wall clock time: 0.9s\n",
      "Downloaded: 1 files, 2.2M in 0.5s (4.92 MB/s)\n"
     ]
    }
   ],
   "source": [
    "# df = pd.read_csv(f'./data/{field_name}/{field_name}_ave.csv')\n",
    "\n",
    "\n",
    "query_dir = f'./data'\n",
    "template_dir = '../data'\n",
    "astrometry_correct = True\n",
    "\n",
    "CSCviewsearch(field_name, RA, DEC, radius, query_dir, template_dir,csc_version='2.0', engine='wget')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "288\n",
      "1816\n",
      "288\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = pd.read_csv(f'{data_dir}/{field_name}_wget.txt', comment='#', sep='\\t', na_values=' '*9)\n",
    "df = df.drop_duplicates(subset=['name']).reset_index(drop=True)\n",
    "df['ra'] = Angle(df['ra'], 'hourangle').degree\n",
    "df['dec']= Angle(df['dec'], 'deg').degree\n",
    "df['name'] = df['name'].str.strip()\n",
    "print(len(df))\n",
    "if astrometry_correct:\n",
    "    # astrometric correction on the stack level \n",
    "\n",
    "    stack_astrometry(field_name, RA, DEC, radius, query_dir,template_dir,plotting=True)\n",
    "\n",
    "    df_PU = pd.read_csv(f'{data_dir}/astrometry/{field_name}_PU.csv')\n",
    "    print(len(df_PU))\n",
    "    df = pd.merge(df, df_PU[['name','RA_new','DEC_new','r0_new','r1_new','ang_new']], on='name')\n",
    "    print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = [(df, field_name, i, data_dir,'name','RA_new','DEC_new','r0_new','r1_new','ang_new',False,False,2,True,False,13) for i in range(len(df))]\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    with mp.Pool() as pool:\n",
    "        arr = pool.map(nway_CSC_matching_merged_mw, args)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process crossmatching results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fields = process_crossmatching(df, data_dir, field_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classify"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "TD = pd.read_csv('../files/CSC_TD_11042023_MW_allcolumns.csv')\n",
    "TD = TD.rename(columns={'GAIA_DR3Name': 'DR3Name_gaia', 'GAIA_rgeo': 'rgeo', 'GAIA_B_rgeo': 'B_rgeo', 'GAIA_b_rgeo': 'b_rgeo', 'GAIA_rpgeo': 'rpgeo', 'GAIA_B_rpgeo': 'B_rpgeo', 'GAIA_b_rpgeo': 'b_rpgeo'})\n",
    "\n",
    "dir_tool = '../files'\n",
    "\n",
    "# tbabs from xpsec Wilms, Allen & McCray (2000)\n",
    "tbabs_ene, tbabs_cross = np.loadtxt(f'{dir_tool}/tbabs.data', skiprows=0)\n",
    "tbabs_cross *= 100\n",
    "\n",
    "df_reds = []\n",
    "df_extinction = pd.read_csv(f'{dir_tool}/extinction_MWbands.csv',index_col='ebv_index')\n",
    "df_reds.append(df_extinction)\n",
    "df_abs = []\n",
    "for band in ['Fcsc_s', 'Fcsc_m', 'Fcsc_h', 'Fcsc_b']:\n",
    "        df_abs_band = pd.read_csv(f'{dir_tool}/abs_{band}.csv',index_col='nH')\n",
    "        df_abs_band = df_abs_band.stack() \n",
    "        df_abs_band= df_abs_band.reset_index().rename(columns={'nH':'nH_index','level_1':'Gamma_col',0:band+'_cor'})\n",
    "        df_abs_band = df_abs_band.set_index(['nH_index','Gamma_col'])\n",
    "        df_abs.append(df_abs_band)\n",
    "df_reds.append(df_abs)\n",
    "\n",
    "#start_t = datetime.datetime.now()\n",
    "\n",
    "\n",
    "Xcat = 'CSC'\n",
    "distance = 'nodist' # 'rgeo_lum'\n",
    "ran_feature = False\n",
    "# seed for generating all randomness, set to none for random seed\n",
    "random_state_sample, random_state_smote,random_state_rf = None, None, None #12, 12, 12 #random_state, random_state, random_state\n",
    "#test = '01162023'\n",
    "Uncer_flag = True\n",
    "red_switch = True\n",
    "apply_limit= True\n",
    "mag2flux_switch= True\n",
    "stand_switch= True\n",
    "# SMOTE oversampling switch\n",
    "oversample_switch = True # True\n",
    "scaler_switch=True\n",
    "color_select = True\n",
    "# physical oversampling switch\n",
    "physical_sample = True\n",
    "Xfeature_only = False\n",
    "missingvalues_replace = True\n",
    "ML_model = 'RF'\n",
    "\n",
    "n_estimators = 1000 # 1000\n",
    "\n",
    "num_sample = 10 #10 for test, 1000 for real run\n",
    "\n",
    "class_labels = ['AGN','CV','HM-STAR','LM-STAR','HMXB','LMXB','NS','YSO'] # there are 8 classes of X-ray sources in our current pipeline \n",
    "\n",
    "version = 'default' # 'default'#   'SMOTE' # lightGBM'\n",
    "\n",
    "# 'Xfeatureonly'  Xfeature_only=  True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run classification in parallel. If crashes, make sure enough memory is allocated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "J1115.1-6118\n",
      "Preprocessing\n",
      "Classifying\n",
      "82.47342801094055\n"
     ]
    }
   ],
   "source": [
    "df_all = pd.DataFrame()\n",
    "# field_name = \n",
    "# for field_name in df_fields['Field'].unique():\n",
    "print(field_name)\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "df_field = df_fields #[df_fields['Field']==field_name].reset_index(drop=True)\n",
    "df_field = df_field.sort_values(by='name').reset_index(drop=True)\n",
    "\n",
    "df_field.to_csv(f'{data_dir}/{field_name}_MW.csv',index=False)\n",
    "\n",
    "df_field['ebv'] = DustMap.ebv(SkyCoord(df_field['CSC_RA'],df_field['CSC_DEC'], unit='deg'), dustmap='SFD') * 0.86\n",
    "\n",
    "# create list of args to pass to multiprocessing pool. assign i to random state variables to set reproducible results\n",
    "args = [(TD,df_field,red_switch,df_field['ebv'].mean(),Xcat,False,distance,Uncer_flag,random_state_sample,random_state_smote,tbabs_ene,tbabs_cross,\\\n",
    "            apply_limit,mag2flux_switch,stand_switch,oversample_switch,scaler_switch,color_select,np.sqrt(2.),physical_sample,df_reds,Xfeature_only,missingvalues_replace) for i in range(num_sample)]\n",
    "\n",
    "\n",
    "print('Preprocessing')\n",
    "if __name__ == '__main__': \n",
    "    with mp.Pool() as pool:\n",
    "        arr = pool.map(class_prepare_FGL, args)\n",
    "        \n",
    "        \n",
    "opts = {'bootstrap': True, 'class_weight': None, 'criterion': 'gini',\n",
    "        'max_depth': None,  'max_leaf_nodes': None, # 'max_features': \"auto\",\n",
    "        'min_samples_leaf': 1, 'min_samples_split': 2,\n",
    "        'min_weight_fraction_leaf': 0.0, 'n_jobs': None,#-1,\n",
    "        'random_state': None, 'verbose': 0, 'warm_start': False,\n",
    "        'n_estimators': n_estimators}\n",
    "\n",
    "\n",
    "arr = [_ for _ in zip(arr, [ML_model]*len(arr), [opts]*len(arr), [False]*len(arr))]\n",
    "print('Classifying')\n",
    "if __name__ == '__main__': \n",
    "    with mp.Pool() as pool:\n",
    "        #res = pool.map(class_train_and_classify, arr)\n",
    "        res = pool.map(class_train_model_and_classify, arr)\n",
    "\n",
    "class_save_res(res, dir_out)\n",
    "end = time.time()\n",
    "print(end - start)\n",
    "\n",
    "#FGL_radius,FGL_ra, FGL_dec = fgl_unas.loc[fgl_unas.FGL_name==field_name, 'Conf_95_SemiMajor'].values[0], fgl_unas.loc[fgl_unas.FGL_name==field_name, 'RAJ2000'].values[0], fgl_unas.loc[fgl_unas.FGL_name==field_name, 'DEJ2000'].values[0]\n",
    "df_class = combine_class_result(field_name, data_dir, class_labels)#,weight_CM=True)\n",
    "\n",
    "df_all = pd.concat([df_all, df_class], ignore_index=True, sort=False)\n",
    "df_XCLASS = df_class.rename(columns={'significance':'Signif.','F_b':'flux_aper90_ave_b','Fcsc_s':'flux_aper90_ave_s','Fcsc_m':'flux_aper90_ave_m','Fcsc_h':'flux_aper90_ave_h','var_intra_prob':'kp_prob_b_max','W1mag':'W1mag_comb','W2mag':'W2mag_comb'})\n",
    "\n",
    "\n",
    "    \n",
    "df_all.to_csv(f'{data_dir}/{field_name}_class.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create visualization website"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(f'{data_dir}/{field_name}_class.csv')\n",
    "\n",
    "df_html = df_all[['name','Class','Class_prob','Class_prob_e','CT','CSC_RA','CSC_DEC','CSC_err_r0','CSC_err_r1','CSC_PA','significance','Fcsc_b','Fcsc_s','Fcsc_m','Fcsc_h','HR_hms','var_intra_prob',\n",
    "       'var_inter_prob','p_any','p_i','MW_RA','MW_DEC','MW_err0','MW_sep','DR3Name_gaia','CATWISE_Name','ALLWISE_AllWISE','TMASS__2MASS','Gmag','BPmag','RPmag','RPlx','PM','rgeo','Jmag','Hmag','Kmag','W1mag','W2mag','W3mag']].rename(columns={'DR3Name_gaia':'Gaia_DR3Name','ALLWISE_AllWISE':'AllWISE_Name','TMASS__2MASS':'TMASS_Name'})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "write_to_html_file(df_html, clusters_dict, field_name, filename=f'./data/{field_name}/{field_name}_class.html')\n",
    "os.system(f'open ./data/{field_name}/{field_name}_class.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ciao-4.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
